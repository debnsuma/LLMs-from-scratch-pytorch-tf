{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf9290e4-c0e7-4b37-bfe8-19e10e53a0d8",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1befa4cd-7cdd-482e-958b-5933f01561d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d1145b1-b988-42e7-a362-0de2c04a0d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for windows/linux \n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a43ad1ee-e20d-402f-80be-25eaaa8d90db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for mac with GPU \n",
    "torch.backends.mps.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba27927-d9ee-4ef7-9214-bb3dc9ad8d9c",
   "metadata": {},
   "source": [
    "## Understanding tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9881f626-7efa-4ea2-bee0-c7dd84ec2182",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch0d = torch.tensor(10)\n",
    "torch1d = torch.tensor([1,2,3,4])\n",
    "torch2d = torch.tensor([[1,2,3], [4,5,6]])\n",
    "torch3d = torch.tensor([[[1,2,3], [4,5,6]], \n",
    "                        [[7,8,9], [10,11,12]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3603d52-d536-4b11-b5ed-25ee20a1c717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch0d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d20c9006-4aa9-4653-b2f5-6eeb7cc6ed81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a44df63f-d5fd-4557-95c8-2801fed1a720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6ce1d90-3f2f-4159-b935-94a8f9fcf4ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  3],\n",
       "         [ 4,  5,  6]],\n",
       "\n",
       "        [[ 7,  8,  9],\n",
       "         [10, 11, 12]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f4ef4a2-5dc1-4184-95b8-c2688e369dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1, 2, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch0d.ndim, torch1d.ndim, torch2d.ndim, torch3d.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8cda754-027f-42d3-8f5c-5b0c67fe4447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.int64, torch.int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch0d.dtype, torch3d.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a89c3fd-ad22-47e9-b50c-97e2a08f5e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "floatvec = torch.tensor([[1,2,3], [4,5,6.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19c9106b-15b3-49a7-9790-5dfdc8d16066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "floatvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e14c5c2-27a7-4423-af88-006c26309d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "floatvec.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e079bfc3-a69e-4781-9763-53754e35d543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "floatvec = torch.tensor([[1,2,3], [4,5,6]], dtype=torch.float32)\n",
    "floatvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d5bc691-5140-43c9-803d-d000fc99d9fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "floatvec.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4bdf3d22-a02f-4fbe-8957-e543211b0cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "floatvec = torch.tensor([[1,2,3], [4,5,6]], dtype=torch.float64)\n",
    "floatvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6278023a-b258-438d-8538-e212d87740c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This will throw an error \n",
    "# # TypeError: tensor(): argument 'dtype' must be torch.dtype, not type\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "# floatvec = torch.tensor([[1,2,3], [4,5,6]], dtype=np.float32)\n",
    "# floatvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed6578cc-884e-48ed-8440-1723cedf5e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "floatvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2b8d382-388f-4042-aef8-263dba66ef6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "floatvec = floatvec.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3aa05ce7-f20f-46bb-b3cd-73a514701e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "floatvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cfbececc-e7d1-4e3c-b80b-13d08a0eb7ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "floatvec.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b7db6d6-7eb5-4ed3-b2c6-121365816944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([]), torch.Size([4]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch0d.shape, torch1d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cc2c06ac-e272-43c5-8b90-3b8a367aafc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch0d.ndim, torch1d.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a2472dd8-5dc7-4d6c-8a31-4e647bf174a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch2d.ndim, torch3d.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6b869db3-b3a2-4cee-bdac-685882405c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), torch.Size([2, 2, 3]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch2d.shape, torch3d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aea6139f-1bfe-4178-921e-53ed8228ef7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4, 5, 6]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch2d.reshape(1,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "da611c07-e926-418a-af2e-159b26833232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch2d.reshape(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0ac7f463-bda0-4abc-9947-56635b85452f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch2d.reshape(3,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3c198dc3-1661-4764-b366-66694a3fdd77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch2d.reshape(-1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "885ee2b6-fd24-4f91-a6eb-803ebd12786a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4, 5, 6]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch2d.view(-1,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1ab16ea4-72ee-42a6-b899-db08b20c5bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4, 5, 6]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch2d.reshape(-1,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dc82dd7c-b3d3-49bf-b521-0b8e597fd37f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  3],\n",
       "         [ 4,  5,  6]],\n",
       "\n",
       "        [[ 7,  8,  9],\n",
       "         [10, 11, 12]]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "48b46069-02f6-45ee-af35-f7753f54d39f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b55798a6-e7b3-463b-a1ca-f18be1835855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 4],\n",
       "        [2, 5],\n",
       "        [3, 6]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch2d.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8ce4268b-7b04-4065-8e75-076a131c21ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "15670382-a2ae-4390-8cbb-c3aa526a2bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6],\n",
       "        [7, 8]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch2d = torch.tensor([[1, 2, 3, 4],\n",
    "                       [5, 6, 7, 8]])\n",
    "\n",
    "torch2d.view(4, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e654ee4a-ac8a-434d-b683-0b72b230424b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch2d = torch2d.view(4, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "11395eed-ff34-4b8a-beee-f0e50b47e8de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6],\n",
       "        [7, 8]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d43edd30-70e1-4e8f-b8ff-f6c12b8b6158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e62bd339-44f4-4628-b837-c11fec2deb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch1d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "01fb5a39-70b3-412a-89e8-143b0489a23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This will error out\n",
    "# # RuntimeError: size mismatch, got input (4), mat (4x2), vec (4)\n",
    "\n",
    "# torch2d.matmul(torch1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "eab48a8e-30c7-4744-ae45-08993c8eaeac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([50, 60])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch1d.matmul(torch2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0333f21d-d04f-4e6e-8d67-9ea8f09294b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch1d.matmul(torch2d).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "06fa28b4-cc2a-402a-ba29-3b5458ad7f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([50, 60])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch1d @ torch2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "64e3e64b-c56f-4645-9cd1-62b0a1bab888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6],\n",
       "        [7, 8]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "22e6e2b5-c652-45e7-9566-8107177d4f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  5,  11,  17,  23],\n",
       "        [ 11,  25,  39,  53],\n",
       "        [ 17,  39,  61,  83],\n",
       "        [ 23,  53,  83, 113]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch2d.matmul(torch2d.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bf5b3958-25b0-405b-97f0-08d520cfd1ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  5,  11,  17,  23],\n",
       "        [ 11,  25,  39,  53],\n",
       "        [ 17,  39,  61,  83],\n",
       "        [ 23,  53,  83, 113]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch2d @ torch2d.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076701f0-6684-4fe5-8105-c98627e1e26f",
   "metadata": {},
   "source": [
    "## Seeing models as computation graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f062189-4d19-46d6-ae85-7801e90ee14c",
   "metadata": {},
   "source": [
    "### A logistic regression forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1cf7e371-4fa0-48cc-adac-e4324802948c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0852)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F \n",
    "\n",
    "y = torch.tensor([1.])\n",
    "x1 = torch.tensor([1.1])\n",
    "\n",
    "w1 = torch.tensor([2.2])\n",
    "b1 = torch.tensor([0.0])\n",
    "\n",
    "z = x1 * w1 + b1\n",
    "a = torch.sigmoid(z)\n",
    "\n",
    "loss = F.binary_cross_entropy(a, y) \n",
    "\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d1fed89c-e8b8-4c5d-953b-f71ac88641e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0852)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F \n",
    "\n",
    "y = torch.tensor([1.])\n",
    "x1 = torch.tensor([1.1])\n",
    "\n",
    "w1 = torch.tensor([2.2])\n",
    "b1 = torch.tensor([0.0])\n",
    "\n",
    "z = x1 * w1 + b1\n",
    "a = torch.sigmoid(z)\n",
    "\n",
    "loss = F.binary_cross_entropy_with_logits(z, y) \n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "899a0b17-23d8-4d12-87d8-0aa7e8ae565e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c2f8be67-4839-4a41-a0ae-b33ba7b248bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.4200])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83513d9-d67b-4144-ac37-d7bd67b31cc8",
   "metadata": {},
   "source": [
    "### Computing gradients via autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6085b1a3-bfa5-4a99-b820-da77aedc7d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.autograd import grad\n",
    "\n",
    "y = torch.tensor([1.])\n",
    "x1 = torch.tensor([1.1])\n",
    "\n",
    "w1 = torch.tensor([2.2], requires_grad=True)\n",
    "b1 = torch.tensor([0.0], requires_grad=True)\n",
    "\n",
    "z = x1 * w1 + b1\n",
    "a = torch.sigmoid(z)\n",
    "\n",
    "loss = F.binary_cross_entropy_with_logits(z, y) \n",
    "\n",
    "# manual way \n",
    "grad_L_w1 = grad(loss, w1, retain_graph=True)\n",
    "grad_L_b1 = grad(loss, b1, retain_graph=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9b482315-e9a1-45b2-a60e-6598a7e842ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_L_w1 : (tensor([-0.0898]),)\n",
      "grad_L_b1 : (tensor([-0.0817]),)\n"
     ]
    }
   ],
   "source": [
    "print(f\"grad_L_w1 : {grad_L_w1}\")\n",
    "print(f\"grad_L_b1 : {grad_L_b1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "dec7f3bc-00e4-42a8-9213-e76003bc8953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_L_w1 : tensor([-0.0898])\n",
      "grad_L_b1 : tensor([-0.0817])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.autograd import grad\n",
    "\n",
    "y = torch.tensor([1.])\n",
    "x1 = torch.tensor([1.1])\n",
    "\n",
    "w1 = torch.tensor([2.2], requires_grad=True)\n",
    "b1 = torch.tensor([0.0], requires_grad=True)\n",
    "\n",
    "z = x1 * w1 + b1\n",
    "a = torch.sigmoid(z)\n",
    "\n",
    "loss = F.binary_cross_entropy_with_logits(z, y) \n",
    "\n",
    "# pytorch way \n",
    "loss.backward()\n",
    "print(f\"grad_L_w1 : {w1.grad}\")\n",
    "print(f\"grad_L_b1 : {b1.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7066a7-6a4e-4492-9b84-ddf0f397632f",
   "metadata": {},
   "source": [
    "### Implementing multilayer neural networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4eab1d4-f98f-4b76-b481-c275d834ab34",
   "metadata": {},
   "source": [
    "![img](./img1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "99bd4030-a3f8-4066-92bd-545f4623d1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "class NeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.layers = torch.nn.Sequential(\n",
    "            #1st Layer \n",
    "            torch.nn.Linear(in_features=num_inputs, out_features=30),\n",
    "            torch.nn.ReLU(),\n",
    "\n",
    "            #2nd Layer \n",
    "            torch.nn.Linear(in_features=30, out_features=20),\n",
    "            torch.nn.ReLU(),\n",
    "\n",
    "            #Output Layer \n",
    "            torch.nn.Linear(in_features=20, out_features=num_outputs)\n",
    "        \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.layers(x)\n",
    "        return logits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "837a04e1-653b-45a9-bedc-d8b52331041f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork(50, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "884c8a41-8261-43cb-9586-53ea9d906b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=50, out_features=30, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=30, out_features=20, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=20, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e8795800-6edd-478d-948e-e4b4e4c4714a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x302eb0040>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total no. of parameters \n",
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f05a3f14-d94b-4539-a7fb-3a86a0c09bf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.1372,  0.0784, -0.0019,  ...,  0.0681, -0.0281,  0.0667],\n",
      "        [-0.0199, -0.0477, -0.0605,  ..., -0.0633, -0.1335, -0.0358],\n",
      "        [-0.0840, -0.0862, -0.0478,  ..., -0.0727, -0.0694, -0.0108],\n",
      "        ...,\n",
      "        [ 0.1237, -0.0767,  0.0859,  ...,  0.1031,  0.0091,  0.0843],\n",
      "        [-0.0719,  0.0441,  0.1113,  ..., -0.0203,  0.0188, -0.0364],\n",
      "        [ 0.0402,  0.0081,  0.1389,  ...,  0.0798, -0.0290,  0.0611]],\n",
      "       requires_grad=True) 30\n",
      "Parameter containing:\n",
      "tensor([ 0.0287,  0.1103,  0.1040, -0.1187, -0.0915,  0.0386, -0.0120,  0.1410,\n",
      "         0.1214, -0.0157, -0.0154, -0.0846, -0.1409, -0.0690,  0.0485, -0.1367,\n",
      "        -0.0757,  0.1102,  0.0872,  0.1344,  0.0535,  0.0403, -0.0702,  0.0319,\n",
      "         0.0166, -0.0580,  0.0715,  0.0268, -0.1381, -0.0508],\n",
      "       requires_grad=True) 30\n",
      "Parameter containing:\n",
      "tensor([[-1.0424e-01, -1.5308e-01, -1.4587e-01,  8.8064e-02,  4.1055e-02,\n",
      "          1.7843e-01,  5.4635e-03, -1.5055e-01,  3.1943e-02,  1.0119e-01,\n",
      "         -1.5551e-01,  1.4269e-01, -2.3016e-02, -4.0759e-02, -1.5125e-01,\n",
      "          1.3583e-01, -8.7498e-02,  1.0438e-01,  3.0921e-02,  3.0698e-02,\n",
      "          1.4117e-01,  5.1390e-02,  7.5504e-02, -1.0517e-01, -1.6030e-01,\n",
      "          2.1666e-02, -2.3868e-02,  2.4404e-02, -1.2050e-01,  8.4868e-02],\n",
      "        [ 9.4481e-02,  1.4594e-01,  3.7386e-02, -1.4347e-01, -1.6130e-01,\n",
      "          1.6686e-01,  1.0458e-01,  5.9807e-02,  1.3292e-01, -1.3017e-03,\n",
      "          1.7972e-01,  1.7292e-01,  1.3931e-01,  1.7854e-01, -5.6371e-02,\n",
      "          8.1928e-02,  3.2481e-03,  1.6356e-01, -3.2772e-02, -5.5052e-02,\n",
      "         -4.2390e-02, -1.3877e-01, -4.6024e-02,  4.5078e-02, -5.6642e-02,\n",
      "          6.0365e-02,  1.7468e-01,  8.0545e-02, -1.6200e-01, -1.6415e-01],\n",
      "        [ 5.4345e-02,  8.4950e-02, -1.9020e-02,  1.1185e-01,  1.1898e-01,\n",
      "          1.3789e-01, -5.7534e-02,  1.7511e-01, -3.6840e-02,  3.7725e-02,\n",
      "         -5.6304e-02,  1.9110e-02,  1.6783e-01, -1.4404e-01,  2.1023e-02,\n",
      "         -3.3668e-02, -1.7056e-02, -1.0839e-01, -9.1480e-02, -1.4623e-01,\n",
      "         -2.5698e-02, -1.1016e-01, -8.9617e-02, -1.5499e-01,  1.6495e-01,\n",
      "          9.8653e-02,  4.2218e-02, -5.9746e-02,  1.1370e-01, -3.9878e-02],\n",
      "        [-1.5301e-01,  8.1923e-02,  1.1668e-01, -1.4642e-01, -1.3301e-01,\n",
      "         -2.9670e-02,  1.3855e-01,  6.3797e-02, -1.6405e-01,  8.2280e-02,\n",
      "          2.6465e-02, -1.2996e-01, -1.7632e-01,  1.0258e-01, -8.8264e-02,\n",
      "          8.1776e-02,  6.3026e-02, -7.1383e-02,  9.5626e-02,  9.0533e-02,\n",
      "          2.5230e-02,  4.4587e-03, -2.5017e-02, -8.5766e-02,  9.0539e-02,\n",
      "          4.1320e-02,  2.5250e-02,  7.8186e-02,  1.6408e-01,  7.4008e-02],\n",
      "        [ 1.4767e-01,  2.6411e-02,  1.6728e-01,  1.8168e-01,  1.2676e-01,\n",
      "          9.0853e-02,  8.2704e-02, -1.7980e-01,  1.3763e-01,  4.0836e-02,\n",
      "          1.8928e-02,  1.9825e-02, -6.5856e-02,  1.1111e-01, -1.6251e-01,\n",
      "          7.2877e-03,  6.9083e-02, -1.1860e-01, -1.4749e-01,  8.3142e-02,\n",
      "         -1.2239e-01,  1.0490e-01, -4.0815e-02, -1.2228e-01,  3.6333e-02,\n",
      "         -1.5018e-01,  5.5465e-02, -9.6570e-02,  1.3330e-01, -1.5542e-01],\n",
      "        [ 2.1779e-02,  6.1378e-02, -1.1189e-01,  1.1238e-01,  1.6466e-02,\n",
      "          6.4999e-02, -6.6279e-02, -1.6183e-01,  1.8082e-01, -1.5597e-01,\n",
      "          1.8228e-02, -1.0116e-01, -2.4795e-02, -1.4245e-01, -1.4314e-01,\n",
      "          1.1809e-01, -1.5810e-01, -1.8207e-01, -4.1106e-03, -1.0488e-01,\n",
      "          1.5253e-01, -9.9123e-02,  2.5247e-02, -1.7479e-01, -1.3995e-01,\n",
      "         -1.6373e-01, -7.5075e-02, -1.7035e-01, -1.6631e-02,  9.6223e-04],\n",
      "        [-1.5649e-01,  1.4501e-01, -1.7936e-01, -7.4539e-02,  1.7565e-01,\n",
      "         -1.6146e-01,  1.7614e-01,  1.5490e-01,  7.3017e-02, -1.5169e-01,\n",
      "          9.2213e-02,  1.6124e-01, -1.5663e-02, -8.3638e-02, -2.0175e-02,\n",
      "         -1.0162e-01,  1.1844e-01,  5.5657e-02,  1.6528e-01,  1.7008e-01,\n",
      "         -1.2742e-01, -1.7621e-02, -1.0676e-01,  1.4472e-02,  1.7954e-01,\n",
      "          2.0917e-02,  1.6020e-01, -1.6322e-01,  1.2786e-01, -5.8028e-03],\n",
      "        [ 1.3206e-01,  1.7375e-01, -4.9050e-02, -6.1932e-02,  5.5710e-02,\n",
      "          8.8697e-02,  3.5860e-02,  8.4778e-02, -2.3726e-02,  9.1541e-03,\n",
      "          1.4602e-01,  1.0160e-02, -5.0259e-02,  1.3488e-01,  9.2580e-02,\n",
      "         -1.6448e-01, -1.7960e-01, -1.4653e-01,  1.6952e-01,  7.7076e-02,\n",
      "          1.6703e-01, -1.4427e-01, -3.2889e-02,  1.5141e-01,  1.5664e-01,\n",
      "         -1.7657e-03, -1.6469e-01, -7.9111e-02, -1.1503e-01,  1.1044e-01],\n",
      "        [ 6.6355e-02,  1.1267e-01, -1.6763e-01, -1.5586e-01, -1.1501e-01,\n",
      "          1.9404e-02, -1.0943e-01,  7.8337e-02, -8.8114e-03,  5.7634e-02,\n",
      "         -1.4258e-01,  8.5214e-02, -1.2290e-01,  6.3625e-02, -3.7649e-02,\n",
      "          1.3902e-01, -1.2677e-02, -1.3353e-01,  8.6077e-02, -5.2216e-02,\n",
      "          4.3257e-02, -1.0896e-01, -9.3305e-02,  3.1372e-02,  1.0646e-01,\n",
      "         -6.5673e-02,  8.4523e-02,  4.7801e-02, -1.7752e-01,  1.2465e-01],\n",
      "        [-1.3313e-01, -8.5248e-02,  1.2836e-02,  1.1526e-01, -8.9915e-02,\n",
      "         -7.8964e-02, -4.3161e-02,  1.6767e-01, -1.1088e-01,  1.6604e-01,\n",
      "          1.6158e-01, -3.9555e-02, -8.3807e-02,  1.5817e-01,  1.3081e-01,\n",
      "         -1.7398e-01,  4.1998e-02,  8.2694e-02, -7.3804e-02,  9.8311e-02,\n",
      "         -1.3095e-01,  7.7213e-02,  1.7197e-02, -1.2395e-02, -6.9889e-02,\n",
      "         -1.6597e-01, -6.8262e-02, -8.2465e-02, -8.8540e-02, -9.9668e-02],\n",
      "        [-1.7990e-01, -1.3070e-01, -1.7604e-01,  1.0274e-01, -8.3657e-02,\n",
      "         -2.6281e-04,  9.8398e-02,  6.0955e-02,  1.4002e-01,  4.4034e-02,\n",
      "          2.0073e-03,  1.4078e-01, -1.5346e-01,  1.3779e-02,  6.3957e-02,\n",
      "         -7.9378e-02,  3.0154e-03, -8.6269e-02,  6.3424e-02,  8.6387e-02,\n",
      "         -1.6408e-01,  9.2559e-02, -1.7770e-01, -5.3426e-02, -1.3154e-01,\n",
      "          7.3533e-03, -4.8413e-03,  1.5351e-02,  2.3932e-02,  4.7707e-02],\n",
      "        [ 1.7548e-01, -4.2858e-02,  3.0783e-02, -1.1007e-01, -4.6375e-02,\n",
      "         -1.5658e-01,  1.1932e-01, -1.8105e-01,  6.8575e-02, -2.4638e-02,\n",
      "          1.1890e-01,  2.2243e-03,  6.6787e-02, -8.9083e-02,  1.4776e-01,\n",
      "         -5.0529e-02, -6.6432e-02,  1.4778e-02,  2.6299e-02,  2.1289e-02,\n",
      "          1.5221e-01,  8.5226e-02, -4.5442e-02,  1.7855e-02, -1.2190e-01,\n",
      "         -6.1899e-02, -2.3519e-03, -1.5390e-01,  1.5378e-02, -1.5971e-01],\n",
      "        [-1.7377e-01,  5.5373e-03, -1.6940e-01, -1.2071e-01,  1.2170e-01,\n",
      "         -6.2459e-02,  1.4530e-01,  1.6414e-01, -1.5229e-01, -1.5888e-01,\n",
      "          1.6836e-01,  1.7414e-01,  3.1562e-02, -2.1160e-02,  5.6721e-02,\n",
      "         -1.4245e-01, -1.2846e-01,  9.8051e-02,  2.2146e-02, -7.0560e-02,\n",
      "          1.0565e-01, -3.1187e-02,  6.9138e-02,  4.6013e-02, -6.9422e-02,\n",
      "         -9.6186e-02,  5.3777e-02, -5.3776e-02, -1.6370e-01,  1.7683e-01],\n",
      "        [-1.7344e-01, -1.0700e-01, -1.6245e-01, -3.5716e-03,  4.1523e-02,\n",
      "         -1.1580e-01,  4.8131e-02, -1.2145e-01,  7.3604e-03, -4.7398e-03,\n",
      "          1.2452e-01, -1.5978e-01,  4.7599e-02,  9.0084e-02,  7.6551e-02,\n",
      "          1.6779e-01, -1.4517e-01, -1.0012e-01, -7.8939e-02,  1.4908e-01,\n",
      "          1.1296e-01, -1.7200e-01, -5.9376e-02, -2.3665e-02, -1.8228e-01,\n",
      "         -2.9480e-02, -1.4941e-01, -5.4585e-02, -1.5795e-04,  9.3519e-02],\n",
      "        [ 1.7013e-01,  9.8773e-03, -8.6601e-02,  1.4444e-01, -1.2250e-01,\n",
      "          1.7444e-01, -3.8970e-02, -9.3172e-02,  1.5579e-01,  7.7525e-02,\n",
      "          1.5713e-01, -1.1915e-01,  8.9487e-02, -6.4538e-02, -1.5176e-01,\n",
      "         -1.8185e-01,  1.2550e-01,  6.9845e-02,  1.7223e-01, -6.5125e-02,\n",
      "          9.2327e-02, -2.3571e-02,  1.7295e-01, -5.6101e-02,  1.3167e-01,\n",
      "         -1.5359e-01, -9.0522e-02,  1.4461e-02, -1.8601e-02,  1.4846e-01],\n",
      "        [-9.0201e-02,  7.2013e-02, -5.8292e-02, -5.5116e-02,  1.4381e-01,\n",
      "         -7.9253e-02,  7.7819e-02, -5.0633e-02,  4.5095e-02, -1.1250e-02,\n",
      "         -1.6645e-01, -1.6088e-01,  8.8692e-02,  6.1827e-02, -1.3772e-01,\n",
      "         -5.5054e-02,  1.7429e-01, -8.7879e-02, -1.7814e-02,  4.3495e-02,\n",
      "         -1.4241e-01,  3.4830e-02, -6.0675e-02, -3.5493e-02,  9.9208e-02,\n",
      "         -1.1324e-01,  1.4643e-01, -2.5061e-02,  2.7111e-02, -1.7483e-01],\n",
      "        [-1.4451e-01, -2.7607e-02, -9.8679e-02, -1.4581e-01,  1.7896e-01,\n",
      "         -8.2000e-02,  8.1472e-02,  5.2729e-02,  1.0520e-01, -1.6909e-01,\n",
      "          8.2466e-02,  4.1112e-02, -1.3742e-01,  4.4497e-03,  1.1154e-01,\n",
      "         -9.3103e-02, -7.9708e-02,  5.4982e-02,  3.1248e-02,  8.8132e-02,\n",
      "          8.2680e-02,  1.6032e-01, -1.3793e-01, -1.4874e-01, -1.5974e-01,\n",
      "         -2.5410e-02,  2.8158e-02,  1.1332e-01,  1.3682e-01, -5.7440e-02],\n",
      "        [ 1.3568e-01,  2.9552e-02,  4.8856e-03, -1.7409e-01,  4.5490e-02,\n",
      "         -1.2676e-01,  1.6989e-01, -1.5523e-02, -1.7000e-01, -3.0677e-02,\n",
      "         -1.7966e-01,  1.6339e-01,  4.2747e-02,  1.7846e-02,  6.4504e-04,\n",
      "          9.6910e-03, -5.5444e-02,  2.0958e-02,  6.9499e-02,  8.3205e-02,\n",
      "         -2.5525e-02, -2.8218e-02,  1.6732e-02, -1.6540e-01, -4.4628e-02,\n",
      "         -4.4588e-02, -3.8550e-03, -2.7549e-03, -5.0488e-03,  1.0389e-02],\n",
      "        [ 1.2607e-01, -1.6759e-01, -1.6580e-02,  1.4656e-01, -1.5222e-01,\n",
      "         -5.0440e-02, -6.6423e-02,  1.6392e-01, -1.9992e-02, -2.1396e-02,\n",
      "         -7.7088e-02, -6.5663e-02, -1.3206e-01,  1.1295e-01,  6.0888e-03,\n",
      "         -9.8823e-02,  2.6282e-02, -7.5446e-02,  1.4799e-01,  1.3173e-01,\n",
      "          3.3608e-02,  1.5514e-01, -1.4633e-01, -1.4266e-01, -1.1314e-01,\n",
      "          5.2637e-03, -1.1170e-02, -1.6323e-01, -1.2837e-01,  1.5606e-01],\n",
      "        [-1.3220e-01, -1.4005e-01,  1.5008e-01,  4.2974e-02, -1.0908e-01,\n",
      "          1.2781e-01,  3.7575e-03, -2.6522e-02,  2.0110e-02, -9.9030e-02,\n",
      "          5.0460e-02,  8.2516e-02,  1.2153e-01, -1.5080e-01,  1.1925e-01,\n",
      "          1.4899e-01, -2.4423e-02, -4.6187e-02,  3.4540e-02,  5.1213e-02,\n",
      "          7.0701e-02,  1.5607e-01, -1.5920e-01, -1.5582e-01, -1.0534e-01,\n",
      "          1.7542e-01,  7.3925e-02, -4.2007e-03, -6.1945e-02, -8.7020e-03]],\n",
      "       requires_grad=True) 20\n",
      "Parameter containing:\n",
      "tensor([ 0.1202, -0.0714,  0.0656,  0.1507, -0.0439,  0.0960, -0.0264, -0.1312,\n",
      "         0.0325,  0.1349,  0.0719, -0.0266,  0.0594,  0.0653,  0.0746,  0.0565,\n",
      "         0.0862, -0.0351,  0.1081, -0.1548], requires_grad=True) 20\n",
      "Parameter containing:\n",
      "tensor([[-0.0275,  0.1140,  0.1149, -0.0901, -0.1956,  0.0098,  0.1779, -0.0152,\n",
      "          0.1753,  0.1393,  0.1232,  0.0789,  0.0812,  0.1199,  0.0351, -0.0985,\n",
      "          0.0825,  0.1565, -0.0342, -0.0518],\n",
      "        [-0.1007, -0.1287,  0.0468, -0.0681,  0.2058, -0.0100, -0.1151, -0.1958,\n",
      "         -0.0830,  0.1895,  0.1774,  0.2025, -0.0005,  0.1648,  0.0330, -0.1693,\n",
      "         -0.1542,  0.0842, -0.0970, -0.1558],\n",
      "        [ 0.0761, -0.0995, -0.1349,  0.0544, -0.1865, -0.0020,  0.0584, -0.0451,\n",
      "          0.0208, -0.1029,  0.1138,  0.0216,  0.0215,  0.0499,  0.1527,  0.0880,\n",
      "          0.2017, -0.1426,  0.1838,  0.1606]], requires_grad=True) 3\n",
      "Parameter containing:\n",
      "tensor([-0.0165, -0.1279, -0.1850], requires_grad=True) 3\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    print(p, len(p))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "225bd377-83d9-4a19-8b02-2c268059c203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 1500\n",
      "30 30\n",
      "20 600\n",
      "20 20\n",
      "3 60\n",
      "3 3\n",
      "Total no. of trainable prams : 2213\n"
     ]
    }
   ],
   "source": [
    "num_params = 0\n",
    "for p in model.parameters():\n",
    "    if p.requires_grad:\n",
    "        print(len(p), p.numel())\n",
    "        num_params += p.numel()\n",
    "\n",
    "print(f\"Total no. of trainable prams : {num_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4e5cf17d-e2b9-4e31-af8b-056532f0dc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of trainable model parameters: 2213\n"
     ]
    }
   ],
   "source": [
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Total number of trainable model parameters:\", num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1b98e9c7-fe3d-4dfd-8599-e4423e94232d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=50, out_features=30, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=30, out_features=20, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=20, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1e9efbbd-3b83-489c-bba0-e2623ba9594f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=50, out_features=30, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=30, out_features=20, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=20, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1dd883de-ce3d-4e71-b1e3-cf480e9a48b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=50, out_features=30, bias=True)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "de680055-ad17-4004-962f-16e10e5fa427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1372,  0.0784, -0.0019,  ...,  0.0681, -0.0281,  0.0667],\n",
       "        [-0.0199, -0.0477, -0.0605,  ..., -0.0633, -0.1335, -0.0358],\n",
       "        [-0.0840, -0.0862, -0.0478,  ..., -0.0727, -0.0694, -0.0108],\n",
       "        ...,\n",
       "        [ 0.1237, -0.0767,  0.0859,  ...,  0.1031,  0.0091,  0.0843],\n",
       "        [-0.0719,  0.0441,  0.1113,  ..., -0.0203,  0.0188, -0.0364],\n",
       "        [ 0.0402,  0.0081,  0.1389,  ...,  0.0798, -0.0290,  0.0611]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "cc2ab600-ade8-4584-b97d-0cb629f68916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=50, out_features=30, bias=True)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "4c52157d-ae81-493e-a4d5-7ebf338fbc97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReLU()"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "668cb05f-e1e1-4041-8558-f67cebb2dddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=30, out_features=20, bias=True)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "766fbdc8-65f5-4362-86cc-1b199f741097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 50])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e69143ca-aec3-47e1-9226-ce26adacb7b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "3b865dbb-4258-4386-a792-9e7ef61a45d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1372,  0.0784, -0.0019,  ...,  0.0681, -0.0281,  0.0667],\n",
       "        [-0.0199, -0.0477, -0.0605,  ..., -0.0633, -0.1335, -0.0358],\n",
       "        [-0.0840, -0.0862, -0.0478,  ..., -0.0727, -0.0694, -0.0108],\n",
       "        ...,\n",
       "        [ 0.1237, -0.0767,  0.0859,  ...,  0.1031,  0.0091,  0.0843],\n",
       "        [-0.0719,  0.0441,  0.1113,  ..., -0.0203,  0.0188, -0.0364],\n",
       "        [ 0.0402,  0.0081,  0.1389,  ...,  0.0798, -0.0290,  0.0611]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ceb5e037-90e2-42e4-b3b0-9efe818ec5ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1372,  0.0784, -0.0019,  0.0563,  0.0942, -0.1250, -0.0641,  0.0099,\n",
       "         0.0156,  0.0787, -0.0928, -0.0025,  0.1321, -0.1354, -0.0797,  0.0535,\n",
       "        -0.0301,  0.0944, -0.0660, -0.0618, -0.0259, -0.0612, -0.1116,  0.0289,\n",
       "         0.1346,  0.0692,  0.0274, -0.1067, -0.1413, -0.0833,  0.0936, -0.0742,\n",
       "        -0.0558,  0.1014,  0.0077, -0.1299,  0.0186, -0.0342, -0.1197,  0.1184,\n",
       "         0.1010,  0.1387, -0.1384, -0.1107,  0.0126, -0.0520,  0.0910,  0.0681,\n",
       "        -0.0281,  0.0667], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "0ffb00cb-c751-4986-9d91-d19d0c54c288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0854, -0.1516, -0.1176]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Forward pass \n",
    "torch.manual_seed(123)\n",
    "\n",
    "X = torch.rand(1, 50)\n",
    "out = model(X)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "6b5a2769-86ac-403f-920c-f15db88c461f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 50]), 2)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X.dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "318085d3-e7a9-4f39-9f89-ab0c84feafe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0854, -0.1516, -0.1176]])\n"
     ]
    }
   ],
   "source": [
    "# For inference \n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model(X)\n",
    "print(out) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "503f7232-1836-491c-b83c-06d4d53698e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3838, 0.3028, 0.3133]])\n"
     ]
    }
   ],
   "source": [
    "# For inference \n",
    "\n",
    "with torch.no_grad():\n",
    "    out = torch.softmax(model(X), dim=1)\n",
    "print(out) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03bed3a-198b-4a87-ad49-523f1f1892fb",
   "metadata": {},
   "source": [
    "### Setting up efficient data loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75325cb7-e86b-4f80-b51b-03b6adf0d3ec",
   "metadata": {},
   "source": [
    "PyTorch implements a Dataset and a DataLoader class. The Dataset class is used to instantiate objects that define how each data record is loaded. The DataLoader handles how the data is shuffled and assembled into batches.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb577a7e-20b3-4cb1-9073-b2447f172815",
   "metadata": {},
   "source": [
    "![](./img2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "34623563-aa62-4bd8-891d-dcfdd4bdf359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a toy dataset (two features and class lable) \n",
    "\n",
    "#Train \n",
    "X_train = torch.tensor([\n",
    "    [-1.2, 3.1],\n",
    "    [-0.9, 2.9],\n",
    "    [-0.5, 2.6],\n",
    "    [2.3, -1.1],\n",
    "    [2.7, -1.5]\n",
    "])\n",
    "\n",
    "y_train = torch.tensor([0, 0, 0, 1, 1])\n",
    "\n",
    "# Test\n",
    "X_test = torch.tensor([\n",
    "    [-0.8, 2.8],\n",
    "    [2.6, -1.6],\n",
    "])\n",
    "\n",
    "y_test = torch.tensor([0, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "2be2c96a-12b7-45b2-9a02-e7743b17d87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ToyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        self.features = X\n",
    "        self.labels = y \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        one_x = self.features[index]\n",
    "        one_y = self.labels[index]\n",
    "\n",
    "        return one_x, one_y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]\n",
    "\n",
    "\n",
    "train_ds = ToyDataset(X_train, y_train)\n",
    "test_ds = ToyDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "2c275eaa-6740-45d4-893e-bf4060b05045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.2000,  3.1000],\n",
       "         [-0.9000,  2.9000],\n",
       "         [-0.5000,  2.6000],\n",
       "         [ 2.3000, -1.1000],\n",
       "         [ 2.7000, -1.5000]]),\n",
       " tensor([[-0.8000,  2.8000],\n",
       "         [ 2.6000, -1.6000]]))"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.features, test_ds.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "c4dc1b9b-cc27-45dd-a147-9f2f01a35cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0, 0, 1, 1]), tensor([0, 1]))"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.labels, test_ds.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "eaf6d2d4-09d3-4ff9-859a-e96c21b82de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-1.2000,  3.1000]), tensor(0))"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "bef7f3c6-fb84-4bc8-ad95-3323697c7733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "d9585baf-a1a4-403d-8ef5-7b0c81f592de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_ds, \n",
    "                         batch_size = 2,\n",
    "                         shuffle=True,\n",
    "                         num_workers=0)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_ds, \n",
    "                         batch_size = 2,\n",
    "                         shuffle=False,\n",
    "                         num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "49035f65-9095-4edb-b210-d3fec050635e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: tensor([[ 2.3000, -1.1000],\n",
      "        [-0.9000,  2.9000]]) tensor([1, 0])\n",
      "Batch 2: tensor([[-1.2000,  3.1000],\n",
      "        [-0.5000,  2.6000]]) tensor([0, 0])\n",
      "Batch 3: tensor([[ 2.7000, -1.5000]]) tensor([1])\n"
     ]
    }
   ],
   "source": [
    "for idx, (x, y) in enumerate(train_loader):\n",
    "    print(f\"Batch {idx+1}:\", x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "e6845047-271c-4fad-8bbc-87c4449effe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.2000,  3.1000],\n",
       "         [-0.9000,  2.9000],\n",
       "         [-0.5000,  2.6000],\n",
       "         [ 2.3000, -1.1000],\n",
       "         [ 2.7000, -1.5000]]),\n",
       " tensor([[-0.8000,  2.8000],\n",
       "         [ 2.6000, -1.6000]]))"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.features, test_ds.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "688f7599-e502-460d-b97b-c75b2321808c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_ds, \n",
    "                         batch_size = 2,\n",
    "                         shuffle=True,\n",
    "                         num_workers=0,\n",
    "                         drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "29407b7f-e61f-402e-a04c-01feca0873ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: tensor([[ 2.3000, -1.1000],\n",
      "        [-1.2000,  3.1000]]) tensor([1, 0])\n",
      "Batch 2: tensor([[-0.5000,  2.6000],\n",
      "        [ 2.7000, -1.5000]]) tensor([0, 1])\n"
     ]
    }
   ],
   "source": [
    "for idx, (x, y) in enumerate(train_loader):\n",
    "    print(f\"Batch {idx+1}:\", x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ca0cd9-e25e-488c-b2fc-ede2c524dcc5",
   "metadata": {},
   "source": [
    "### A typical training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "ab3296b8-fe7f-459a-9881-3d2249fa2b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_ds, \n",
    "                         batch_size = 2,\n",
    "                         shuffle=True,\n",
    "                         num_workers=0,\n",
    "                         drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "ac72efc0-07a0-4684-85a6-1dc6355d1b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/003 | Batch 000/002 | Train Loss: 0.75\n",
      "Epoch: 001/003 | Batch 001/002 | Train Loss: 0.65\n",
      "Epoch: 002/003 | Batch 000/002 | Train Loss: 0.44\n",
      "Epoch: 002/003 | Batch 001/002 | Train Loss: 0.13\n",
      "Epoch: 003/003 | Batch 000/002 | Train Loss: 0.03\n",
      "Epoch: 003/003 | Batch 001/002 | Train Loss: 0.00\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = NeuralNetwork(num_inputs=2, num_outputs=2)\n",
    "optimizer = torch.optim.SGD(model.parameters(), \n",
    "                            lr=0.5)\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch, (x, y) in enumerate(train_loader):\n",
    "\n",
    "        logits = model(x)\n",
    "        \n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Logging \n",
    "        print(f\"Epoch: {epoch+1:03d}/{num_epochs:03d}\"\n",
    "              f\" | Batch {batch:03d}/{len(train_loader):03d}\"\n",
    "              f\" | Train Loss: {loss:.2f}\")\n",
    "    model.eval()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "60e3b3ad-00f0-4e71-9bb3-ce2f68475c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of trainable model parameters: 752\n"
     ]
    }
   ],
   "source": [
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Total number of trainable model parameters:\", num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "41cbb2a3-7533-44a2-a713-1334c8c2f74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.8569e+00, -4.1618e+00],\n",
      "        [2.5382e+00, -3.7548e+00],\n",
      "        [2.0944e+00, -3.1820e+00],\n",
      "        [-1.4814e+00, 1.4816e+00],\n",
      "        [-1.7176e+00, 1.7342e+00]])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_train)\n",
    "\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "f5968fcb-3dd9-46b9-84c0-4aa43fc49313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.9911e-01, 8.9419e-04],\n",
      "        [9.9815e-01, 1.8458e-03],\n",
      "        [9.9491e-01, 5.0852e-03],\n",
      "        [4.9127e-02, 9.5087e-01],\n",
      "        [3.0714e-02, 9.6929e-01]])\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode=True)\n",
    "probas = torch.softmax(outputs, dim=1)\n",
    "print(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "0cf49fb4-acb6-407b-a751-e1a3eedd5507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+00, 0.0000e+00],\n",
       "        [1.0000e+00, 0.0000e+00],\n",
       "        [1.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 1.0000e+00],\n",
       "        [0.0000e+00, 1.0000e+00]])"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.round(probas, decimals=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "4496c59d-2335-4b17-9f50-db49afc5abc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "predictions = torch.argmax(outputs, dim=1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "65b362c4-a88e-4168-a12f-55975b6e17e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "predictions = torch.argmax(probas, dim=1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "f2b9d2c1-629a-4d2d-8704-6201a0a22894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "af73040f-4433-4a40-8953-ee0559110c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(predictions == y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "a30ae9f3-d397-4dcc-9006-26384c16ecf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, dataloader):\n",
    " \n",
    "    model = model.eval()\n",
    "    correct = 0.0\n",
    "    total_examples = 0\n",
    "    \n",
    "    for idx, (features, labels) in enumerate(dataloader):\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(features)\n",
    "        \n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "        compare = labels == predictions\n",
    "        correct += torch.sum(compare)\n",
    "        total_examples += len(compare)\n",
    " \n",
    "    return (correct / total_examples).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "dd6c8f27-a61d-45d8-9ca8-fddbd24c785e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(compute_accuracy(model, test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187a191c-58bc-4ab9-bb19-ddd6153c7b77",
   "metadata": {},
   "source": [
    "### Saving and loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "d417bbc9-115b-45bd-b3d3-73938edaae44",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "73065adc-ee6f-48b2-8c17-cc484cf64115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork(2, 2)\n",
    "model.load_state_dict(torch.load('model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "45088e9e-eeaa-46d1-9c7b-8b16ee8ad736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.4088e+00, -3.5848e+00],\n",
       "        [-1.7179e+00, 1.7334e+00]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "f6adbf29-1b5e-4b1d-80f1-8589514c87d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(compute_accuracy(model, test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99940dbc-1ddc-4e4d-9f7e-91055090a001",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
